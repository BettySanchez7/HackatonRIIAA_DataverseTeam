{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Firmas_r1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od1EGY9dguFh"
      },
      "source": [
        "##***MODELO DE DETECCION Y CONTORNEO DE FIRMAS EN IMÁGENES DE DOCUMENTOS*** \n",
        "---\n",
        "En este presente Colab lo que tratamos de construir es un modelo para detectar las firmas existentes de las fotogafías de los documentos 'Expedientes' y poder tener una mejor visualizacion, una vez identificada creamos un recuadro donde se aloja la firma en la imagen.\n",
        "Para esto ocupamos **OpenCv** *(biblioteca libre de visión artificial)* y **Scikit-image** *(colección de algoritmos para el procesamiento de imágenes)*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjEQ3dBAMSRb"
      },
      "source": [
        "#Paso 1:\n",
        "Importamos las imágenes desde nuestra carpeta en Drive para usarlo en el modelo.\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNB3gH2tgkKQ",
        "outputId": "65640fc2-da2d-4541-87b7-5fccde9b1276"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#4/1AX4XfWjuLcZ3Z5ifH8zcDp-ZPqc_GrhjQZ2uMetoG65xRfLuc3isOJM0WEs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEH0YKiSLRGY"
      },
      "source": [
        "\n",
        "in_dir= 'drive/MyDrive/Datos - Hackathon JusticIA/Expedientes'\n",
        "def ls(ruta = getcwd()):\n",
        "    return [abspath(arch.path) for arch in scandir(ruta) if arch.is_file()]\n",
        "lista=ls(in_dir)\n",
        "print(len(lista))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8nO8fLELHnI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS6HBGq2M8FQ"
      },
      "source": [
        "#Paso 2\n",
        "Importamos las Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG_oXg1TgxAq"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import measure, morphology\n",
        "from skimage.color import label2rgb\n",
        "from skimage.measure import regionprops\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import scipy \n",
        "import math\n",
        "import  PIL\n",
        "from PIL import Image \n",
        "import pandas as pd\n",
        "from os import scandir, getcwd\n",
        "from os.path import abspath\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW0pTM5uhpmA",
        "outputId": "ea99b7cf-656e-4aeb-8433-729200dbebf5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeeBx9mTK_GJ"
      },
      "source": [
        "#Paso 3\n",
        "  Implementación del Modelo, *EXTRACCION Y CONTORNEO DE FIRMAS EN UNA IMAGEN BASADO EN EL ANÁLISIS DE COMPONENTES CONECTADOS*\n",
        "\n",
        "  Para esta parte lo primero que hacemos es crear un ciclo para acceder a las imágenes de la carpeta.\n",
        ">Idea del modelo\n",
        "  >>PARTE 1: En esta primera parte aplicaremos el concepto de análisis de componentes conectados, aplicando distintos filtros y discriminando componentes pequeños conectados (letras, rayones, etc.), nos quedamos con los componentes mas grandes conectados, en este caso las *firmas*, dándonos como resultado una imagen binaria donde solo se muestra el fondo blanco y los componentes conectados (firmas) en color negro.\n",
        "\n",
        "  >>PARTE 2: Para la ultima parte recibimos la imagen umbralizada de la primera parte, en esta buscamos los contornos y los seleccionamos en rectángulos encerrando el área de las firmas. \n",
        "  >Finalmente guardamos las imágenes en un .csv para que se pueda descargar y visualizar.\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Qvx9sjgxNC"
      },
      "source": [
        "\"\"\"Extract signatures from an image.\"\"\"\n",
        "file = fileList[:900]\n",
        "path = \"/content/drive/MyDrive/Datos - Hackathon JusticIA/Expedientes\"\n",
        "\n",
        "t = 0\n",
        "i = 0\n",
        "for test in file:\n",
        "    #PARTE 1\n",
        "    ##píxeles conectados de tamaño pequeño\n",
        "    constant_parameter_1 = 84\n",
        "    constant_parameter_2 = 250\n",
        "    constant_parameter_3 = 100\n",
        "    #píxeles conectados de gran tamaño\n",
        "    constant_parameter_4 = 18\n",
        "    # read the img\n",
        "    img = cv2.imread(test, 0)\n",
        "\n",
        "    img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]  \n",
        "\n",
        "    #Analisis de componentes conectados        \n",
        "    blobs = img > img.mean()\n",
        "    #Etiqueta las regiones conectadas de una matriz\n",
        "    #nos devuelve una matriz etiquetada, donde a todas las regiones conectadas se les asigna el mismo valor entero.\n",
        "    blobs_labels = measure.label(blobs, background=1)  \n",
        "    #Devuelve una imagen RGB donde se pintan etiquetas codificadas por colores sobre la imagen.\n",
        "    image_label_overlay = label2rgb(blobs_labels, image=img)\n",
        "    #\n",
        "    fig, ax = plt.subplots(figsize=(10, 6)) #nro col, nro fil\n",
        "    #Inicializamos parámetros iniciales\n",
        "    the_biggest_component = 0\n",
        "    total_area = 0\n",
        "    counter = 0\n",
        "    average = 0.0\n",
        "    #\n",
        "    for region in regionprops(blobs_labels):\n",
        "        if (region.area > 10):\n",
        "            total_area = total_area + region.area\n",
        "            counter = counter + 1\n",
        "            \n",
        "        #toma las regiones con áreas suficientemente grandes\n",
        "        if (region.area >= 250):\n",
        "            if (region.area > the_biggest_component):\n",
        "                the_biggest_component = region.area\n",
        "\n",
        "    #sacamos la media de la áreas pequeñas y el componente más grande lo ponemos en the_bigest_component\n",
        "    average = (total_area/counter)   \n",
        "\n",
        "    #calulamos las proporciones de la áres\n",
        "    # se utiliza como valor umbral para eliminar los píxeles conectados más pequeños, tambien para documentos grandes como el a4\n",
        "    a4_small_size_outliar_constant = ((average/constant_parameter_1)*constant_parameter_2)+constant_parameter_3    \n",
        "    # cálculo de la relación\n",
        "    # se utiliza como valor umbral para eliminar los píxeles conectados más granes,\n",
        "    a4_big_size_outliar_constant = a4_small_size_outliar_constant*constant_parameter_4   \n",
        "\n",
        "    # eliminar los píxeles conectados son más pequeños que a4_small_siz...\n",
        "    pre_version = morphology.remove_small_objects(blobs_labels, a4_small_size_outliar_constant)\n",
        "    # eliminar los píxeles conectados son más grandes que a4_big_siz...\n",
        "    #para deshacerse de los píxeles conectados no deseados, como las cabeceras de las tablas, etc\n",
        "    component_sizes = np.bincount(pre_version.ravel())\n",
        "    too_small = component_sizes > (a4_big_size_outliar_constant)\n",
        "    too_small_mask = too_small[pre_version]\n",
        "    pre_version[too_small_mask] = 0\n",
        "    # guardamos la pre version\n",
        "    #como considerando componentes conectados\n",
        "    cv2.imwrite('pre_version.png', pre_version)    \n",
        "    img = cv2.imread('pre_version.png', 0)    \n",
        "    #Aplicamos nuevamente umbralizaxcion binario inversa\n",
        "    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "    #fin mmodelo de deteccion de firma\n",
        "    #PARTE 2\n",
        "    #recuadro de la firma \n",
        "    #preguntamos si la imagen no esta vacía    \n",
        "    if img  is None:      \n",
        "      continue\n",
        "    else:\n",
        "      #guardamos la imagen\n",
        "      #cv2.imwrite(\"./outputs/output.png\", img)     \n",
        "\n",
        "      # cargar la imagen, convertirla a escala de grises y difuminarla para eliminar el ruido\n",
        "      image = img\n",
        "      test_img_h, test_img_w, test_img_ch = np.array(img).shape\n",
        "      #convertirlo a escala de grises\n",
        "      gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "      gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "\n",
        "      # aplicamos umbralizacion\n",
        "      ret,thresh1 = cv2.threshold(gray ,127,255,cv2.THRESH_BINARY_INV)\n",
        "\n",
        "      # dilatar las porciones blancas\n",
        "      dilate = cv2.dilate(thresh1, None, iterations=2)\n",
        "\n",
        "      # buscamos contornos de la imagen\n",
        "      cnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL,\n",
        "          cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "      cnts = cnts[0] \n",
        "      #creamos una copia de la imagen\n",
        "      orig = image.copy()      \n",
        "      y = 1\n",
        "      for cnt in cnts:\n",
        "          #Comprueba el área del contorno, si es muy pequeña la igonoramos\n",
        "          if y < 15:\n",
        "            #Comprueba el área del contorno, si es muy pequeña la igonoramos\n",
        "            if(cv2.contourArea(cnt) < 100):\n",
        "                continue\n",
        "\n",
        "            # filtramos los contornos de la imagen\n",
        "            x,y,w,h = cv2.boundingRect(cnt)\n",
        "\n",
        "            # tomamos la region de interes de los contonos como rectangulo\n",
        "            roi = image[y:y+h, x:x+w]\n",
        "            #imagen final\n",
        "            roi = cv2.rectangle(orig,(x,y),(x+w,y+h),(0,255,0),2)        \n",
        "         \n",
        "            # Save your contours or characters\n",
        "            cv2.imwrite(\"roi\" + str(i) + \".png\", roi)\n",
        "            #print('i: ',i)\n",
        "            pic_narray = np.array(roi)\n",
        "            listanames.append(roi)\n",
        "            listawidth.append(test_img_w)\n",
        "            listaheight.append(test_img_h)\n",
        "            listaxmin.append(x)\n",
        "            listaymin.append(y)\n",
        "            listaxmax.append(x+w)\n",
        "            listaymax.append(y+h)\n",
        "            listaetiqueta.append(\"Signature\")\n",
        "            i = i + 1      \n",
        "            y = y +6\n",
        "          else:        \n",
        "            break\n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn8GYP4XBl4r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJKzrUdNj-Tn"
      },
      "source": [
        "datafiles = {'filename':listanames, 'width':listawidth, 'height': listaheight, 'etiqueta':listaetiqueta, 'xmin':listaxmin, 'ymin':listaymin, 'xmax':listaxmax, 'ymax':listaymax}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6KG5C7kmKKj"
      },
      "source": [
        "#PASO 4\n",
        "Guardamos las imágenes en un dataframe y lo exportamos en un .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBCZjgwe72do",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "3cec26b8-e88c-4419-dec1-de8174ff4fdc"
      },
      "source": [
        "dffiles= pd.DataFrame(datafiles)\n",
        "dffiles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>etiqueta</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
              "      <td>389</td>\n",
              "      <td>491</td>\n",
              "      <td>Signature</td>\n",
              "      <td>191</td>\n",
              "      <td>431</td>\n",
              "      <td>209</td>\n",
              "      <td>440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
              "      <td>389</td>\n",
              "      <td>491</td>\n",
              "      <td>Signature</td>\n",
              "      <td>182</td>\n",
              "      <td>417</td>\n",
              "      <td>242</td>\n",
              "      <td>430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
              "      <td>389</td>\n",
              "      <td>491</td>\n",
              "      <td>Signature</td>\n",
              "      <td>342</td>\n",
              "      <td>234</td>\n",
              "      <td>360</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            filename  width  ...  xmax ymax\n",
              "0  [[[255, 255, 255], [255, 255, 255], [255, 255,...    389  ...   209  440\n",
              "1  [[[255, 255, 255], [255, 255, 255], [255, 255,...    389  ...   242  430\n",
              "2  [[[255, 255, 255], [255, 255, 255], [255, 255,...    389  ...   360  242\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwB8lxEYPfYb"
      },
      "source": [
        "#print(dffiles.index)\n",
        "dffiles.to_csv (r'/export_dataframe.csv', index = False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fdWkCx1IPmBa",
        "outputId": "b83c7484-16e5-4f89-8fc3-0bc3074fbdba"
      },
      "source": [
        "#guardamos la imagen como array y lo convertimos para poder visualizar y/o modificar :)\n",
        "#im0 = dffiles.iloc[0, 0]\n",
        "#print(im0)\n",
        "#data = Image.fromarray(im0)\n",
        "#plt.imshow(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]\n",
            "\n",
            " [[255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  ...\n",
            "  [255 255 255]\n",
            "  [255 255 255]\n",
            "  [255 255 255]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbe144bf310>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANQAAAD8CAYAAAAPIYpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWZElEQVR4nO3df3DU9Z3H8ed7N8kGkpAApvxIoMECJz+qCKnFqj1BdLCtAh1rZRx1HG+UXp3x2rMVrjd345wdtTNXrnU6ttzhiFet2DuvMFbHIuhZDwWDWEQRjVRK+FECJCFACNns+/7Yb+ISQ0ngE3YDrwezs5/v5/vd3feGfeXz/X72u1lzd0QkjFi2CxA5myhQIgEpUCIBKVAiASlQIgEpUCIB9UmgzGy2mW01s1ozW9gXjyGSiyz0+1BmFgc+AK4G6oA3gfnu/l7QBxLJQX0xQl0C1Lr7Nnc/BjwNzOmDxxHJOXl9cJ8VwI6M5Trgi3/pBuedd55XVVX1QSki4X388cfs27fPulvXF4HqETO7E7gTYPTo0dTU1GSrFJFeqa6uPuG6vtjl2wmMyliujPqO4+5L3L3a3avLy8v7oAyRM68vAvUmMM7MxphZAXATsLIPHkck5wTf5XP3pJndDbwIxIHH3P3d0I8jkov65BjK3Z8Hnu+L+xbJZTpTQiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokIAVKJCAFSiQgBUokoJMGysweM7O9ZrY5o2+Ima0ysw+j68FRv5nZT82s1sw2mdnUvixeJNf0ZIR6HJjdpW8hsNrdxwGro2WAa4Fx0eVO4NEwZYr0DycNlLu/Chzo0j0HWBa1lwFzM/qf8LQ3gDIzGxGqWJFcd6rHUMPcfXfU3gMMi9oVwI6M7eqiPpFzwmlPSri7A97b25nZnWZWY2Y19fX1p1uGSE441UD9uWNXLrreG/XvBEZlbFcZ9X2Kuy9x92p3ry4vLz/FMkRyy6kGaiVwW9S+DViR0X9rNNs3HWjK2DUUOevlnWwDM/sVcCVwnpnVAf8MPAQ8Y2Z3ANuBG6PNnwe+AtQCR4Db+6BmkZx10kC5+/wTrLqqm20d+PbpFiXSX+lMCZGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYAUKJGAFCiRgBQokYBOGigzG2VmL5vZe2b2rpndE/UPMbNVZvZhdD046jcz+6mZ1ZrZJjOb2tdPQiRX9GSESgJ/7+4TgenAt81sIrAQWO3u44DV0TLAtcC46HIn8GjwqkVy1EkD5e673f2tqN0MbAEqgDnAsmizZcDcqD0HeMLT3gDKzGxE8MpFclCvjqHMrAq4GFgHDHP33dGqPcCwqF0B7Mi4WV3U1/W+7jSzGjOrqa+v72XZIrmpx4Eys2Lgv4G/c/eDmevc3QHvzQO7+xJ3r3b36vLy8t7cVCRn9ShQZpZPOkxPuvuzUfefO3blouu9Uf9OYFTGzSujPpGzXk9m+QxYCmxx9x9nrFoJ3Ba1bwNWZPTfGs32TQeaMnYNRXrM3TsvqVTqU8sdfZntbMvrwTaXAbcA75jZ21HfPwAPAc+Y2R3AduDGaN3zwFeAWuAIcHvQiuWclRkYd8fMOvvSv/ez76SBcvfXgBNVe1U32zvw7dOsS6RTe3s7TU1NFBYW0tbWRjKZJD8/n4KCAlKpFIlEgng8nu0ygZ6NUCJZdejQIX74wx8Sj8cZMGAADQ0NFBUVUVZWRiqV4q677mLIkCHZLhPQqUfSD7S1tVFaWsqxY8dIJBLEYjEmTJjAgQMHaGlpobi4ONsldtIIJTkvPz+fOXPmsH//fvbv38+wYcMoLi7mkksuoaioKGd290CBkhzn7pSUlHDhhRcCfGoioqPdMUmRbQqU5DQzOy4oXYOTCyHKpEBJzuouLLkWoK40KSESkEYoOSv15qyJkKOeAiVntUYa+Qk/4SAHT7jNNKZxEzcR5/RnCxUoOSt1jFCrbBX/0v4vFH5QyID8AQwaNIj9+/eTTCYZUDiAQ4WHGDx6MNdyLUM4/TeHFSg5K5kZzc3NNNJIXiqPGQ/PYLAPZtasWfzmN79h9OjRNDc38/6F71N7Ty3eu08fnZAmJeSs9frrr7NixQqIQfXV1RR/tpj/fed/aStpY1PdJoo/W4wNCjtrqBFKzlozZsygKdnEqgGrWHzTYtrb2kmlUiSTSdydN/LeIJWXopLKIMdPoEDJWSw/P585eXP4H/6HI/EjWNxIeeqTWT0HDMb6WEqtNMhjKlByViuwAq71a4/v9Oi0JbyzbSf8hFLvKFBy1uv6PlPHOYAd/XofSuQkThaSvjqFSbN8IgEpUCIBKVAiASlQIgEpUCIBKVAiASlQIgEpUCIBKVAiASlQIgEpUCIBKVAiAenkWMlZp/J9T9n+u30KlOS8VCpFXV0dra2tlJWVMXDgQNydeDxOLBYjPz//U39hNlsUKMlp7k57ezuPP/44W7ZsobKykuHDh7Nv3z7y8vI4fPgw9913H5/5zGeyXSqgQEk/0N7ezsGDB/nyl79MVVUVu3btYtCgQWzfvp2SkhIKCwtzYnQCBUr6AXdn+vTpTJ48mbKyMmpra7nyyisxs85dvlxhufBFv9XV1V5TU5PtMiTHdHxBdeZyLBbr9rt2++Lj7CdSXV1NTU1Ntw/Uk2+BLzSz9Wb2BzN718zuj/rHmNk6M6s1s+VmVhD1J6Ll2mh9VcgnI+eezLB093U2md8TlW09eR+qFZjp7hcBU4DZZjYdeBhY7O5jgQbgjmj7O4CGqH9xtJ3IKckMU9eR6EyPTD1x0kB52qFoMT+6ODAT+K+ofxkwN2rPiZaJ1l9lufJspV/JDE1PL9nWozMlzCxuZm8De4FVwEdAo7sno03qgIqoXQHsAIjWNwFDu7nPO82sxsxq6uvrT+9ZiOSIHgXK3dvdfQpQCVwCXHC6D+zuS9y92t2ry8vLT/fuRHJCr87lc/dG4GXgUqDMzDqm3SuBnVF7JzAKIFpfCuwPUq1IjuvJLF+5mZVF7QHA1cAW0sG6IdrsNmBF1F4ZLROtX+O5MgUj0sd68sbuCGCZmcVJB/AZd3/OzN4DnjazB4CNwNJo+6XAf5pZLXAAuKkP6hbJSScNlLtvAi7upn8b6eOprv1HgW8EqU6kn9HnoUQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAlKgRAJSoEQCUqBEAupxoMwsbmYbzey5aHmMma0zs1ozW25mBVF/IlqujdZX9U3pIrmnNyPUPcCWjOWHgcXuPhZoAO6I+u8AGqL+xdF2IueEHgXKzCqBrwL/ES0bMBP4r2iTZcDcqD0nWiZaf1W0vchZr6cj1L8B3wdS0fJQoNHdk9FyHVARtSuAHQDR+qZoe+kH3L1XFzneSQNlZl8D9rr7hpAPbGZ3mlmNmdXU19eHvGsJIDMwClPP9WSEugy43sw+Bp4mvav3E6DMzPKibSqBnVF7JzAKIFpfCuzveqfuvsTdq929ury8/LSehITl7pgZTU1N7N+/n/b29uPWyYmdNFDuvsjdK929CrgJWOPuNwMvAzdEm90GrIjaK6NlovVrXP8Lp6ynu10hRxAzw91Zvnw5Dz74IG+99Rb19fU0NzezZMkSXnvtNQXrBE7nfaj7gO+aWS3pY6SlUf9SYGjU/11g4emVKF1fvO5OW1sbLS0tHDx4kKamJlpbW4M/bnFxMSUlJTz33HNs3ryZXbt2sWfPHnbv3q1AnUDeyTf5hLu/ArwStbcBl3SzzVHgGwFqO+dlvmjdnWQyye7du3nnnXf4+OOPyc/PJ5VKceDAAQ4dOsSNN97IRRddRIhJ1ZaWFrZs2UJbWxvz589n3759PPnkkxQUFJBKpRSoE+hVoCQ7kskkmzZtYt26dRQXFzNhwgS+9KUvUVxcTCwWo729ne3bt7N8+XImTpxILBYjL+/U/2t37tzJihUrmDFjBlOnTuW1115jz549fO9736OwsJB4PE4sppNsuqNAZdlf+k3v7mzbto2XXnqJeDzOnDlzGDlyZOf6jmOdFmvhnYp3eCH2Amv/fS0DBw7khhtuoGRQSa/rOXz4ML/9v98yZdYUDp1/iHtX3svQoUO57NrLeDX+KnnkcYVdQRFFp/R8z3aWC0N3dXW119TUZLuMrOg6gdAZkpYWXnzxRQ4cOMDs2bMZMWJE56jQMQt35MgRXn/9dR4rfYxfV/+agT6QlqMtxGNxkskk+fn5JJNJEoUJYhbj2LFjHGs7RnFR8XG7hcn2JC1HWigqKuoc8VqPtTJgwACM43cfD9thHuZhvst3z8wPKAdVV1dTU1PT7X61Rqgc0hGubdu28bvf/Y7x48fzta99rXP3rSN4hw8fZv369bzyyis0NTVRN6+OyiOV3PzEzbz6yqtccMEFDB48mNLSUj744ANmzZpF7Ye1rH9zPa2trfzo4R/RnmqnsaGRkRUjefTRR2k+2MzChen5oyf+8wkMY/ql05k2dRoWM1KpFBY3ZvtsGqwhaz+jXKdAZUHXvYKO0SKVSrFhwwbWrl3LvHnzGD16dOe6jtts2bKFxYsXY2ZMmjSJb37zmzw5/kl+tuNnNG5t5Pu3fJ9p06bxyCOP8NwzzzFr1iwGHR7E5pc2c2TfEcaOHcvjDz1ObW0t06ZNIx6PM/EzE7n57ptpbm7mkUceYc2aNZSVlRHbG2PmhJm8+eabNDQ0cP2868m3fHBwTr5ncy6ecaZA5YCOGbyVK1fS2NjI7bffTmlp6XHbmBlHjx7l6aefZt68eUyZMoXhw4enJyDIY8yYMfz4X39MnuXh7tx111185zvfYciQIRw8eJBjx45RUVFBIpFg2bJlFBUV0dTURHNzM1/4whd46qmn2LhxI2+99RYVFRVcccUVjBw5kvvvv5+SkhIuv/xylv7HUvZ9fR8+xGk91sof//hHEokEY8aMydJPLvcoUFnUMeokk0mef/55Dh8+zC233EJ+fn7nNpm/5ROJBIsWLSKRSHzqeKrzQvp69OjRnbcrKyvj61//OgAfffQRO3bsYNKkSdx9993s3buXBx54gPr6eq6//noASktLOXjwII2Njbz99ttcc801LFu2jJ17dtI+p53X33idB198kPXr17No0SKqqqqOG0nPxZGpgwKVJR0vvPb2dlauXMnRo0eZP38+eXl5x70gM1+gZkZhYSGpVIpUKvVJqHB2227+0f+xcxKh62SCW/r4bEfBDuq+XUflFytZXLSY7Ue2s+bqNcycMZOdn91JcbKYtlQbnpfeflTDKHaV7mJgy0CGNg7l6OCjTLloCvd+/l5WrVrF73//e0pLS/nc5z7HwIEDP1XzuUaByiJ3509/+hMNDQ3ceuutx41Mf8mGDRvYuHEjLS0tJBIJ6vLraK5u5pfDfsnIESPZyU52s/vTNzRgdPqymc1MZCJWZVT9TRXbon+fekUMj64HAEPgAr+AuflzKfIirrvuOsaNG8e7777L6tWrqays5NJLL6WiooJzlQKVZdu3b8fMaGhooLW1lbq6OkpKSpg8efIJf8sXFRV1HgO9//77pI6muH7N9cydN5drrrmGxaWLeWDbA0z7+TSqp1azdetWxo8fT/2+ejbUbMBuNwZdOYi1rCVOHHODXgwoRnr7vLw8Jk+ezMSJEzly5Ajbtm2jqalJgZIzr+P9pqlTp/Lee++xZMkS8vPzmTx5Mueffz7Acbt1mYYPH877779PRUUFu3btIpVKkUwmeeG3LzD2/LHYNCPRlsBfdVJNKUYdHYXvci77q8to3t1MU0sTrbRiGLHodM6uu4gnLvyTZscxYCwWo6ioiM9//vOdz+1cpUBlkZlRUlLCggULaG9vJxaLHRegE70whwwZwn333UcsFmP27NnE43H27NlDW1sbEyZM4FeHf0XewDwunnsxU6ZMobCwkD179rBh8waSo5K0JFo6gxTyucAn76Wdq6FSoLKsY3aup+fGdbxQS0rSpxWNGTMmPXkwahSHDh3i2WefZfuo7Rz966P88vu/5KnYU0D6hd7+jXY85XjcmWkziXnsuPsM9XzOZQpUFpzqi67r7TpGg1QqxdatW1myZAnXXXcdSy9dyj3cQ3u8PePGHPdhnfGMJ2axnu/q9aAeUaD6rY7jl2PHjrF69WrWrl3LggULGDduHLFYjMu5/LTCIqdGgepHup6y1NjYyC9+8QsSiQT33ntv59kVGjmyRx9q6WdSqfQfntqxYwc/+MEPKC0tZcGCBZSVlXUej0n2aITqZ2KxGE1NTTz00ENcddVVfPWrX6WgoKBzvQKVXQpUP+PuFBYW8q1vfYtJkyYd168wZZ8C1c+YGYlEgsmTJ2e7FOmGAtWPaATKfZqUEAlIgRIJSIESCUiBEglIgRIJSIESCUiBEglIgRIJSIESCUiBEglIgRIJSIESCUiBEglIgRIJKCe+cM3MmoGt2a6jl84D9mW7iF5QveF81t3Lu1uRK5+H2uru1dkuojfMrKY/1ax6zwzt8okEpECJBJQrgVqS7QJOQX+rWfWeATkxKSFytsiVEUrkrJD1QJnZbDPbama1ZrYw2/UAmNljZrbXzDZn9A0xs1Vm9mF0PTjqNzP7aVT/JjObmoV6R5nZy2b2npm9a2b39IOaC81svZn9Iar5/qh/jJmti2pbbmYFUX8iWq6N1led6Zp7pOMbHLJxAeLAR8D5QAHwB2BiNmuK6voyMBXYnNH3I2Bh1F4IPBy1vwK8QPr7LaYD67JQ7whgatQuAT4AJuZ4zQYUR+18YF1UyzPATVH/z4FvRe2/BX4etW8Clmf7ddLt88rqg8OlwIsZy4uARdn+oUS1VHUJ1FZgRNQeQfq9M4BfAPO72y6Lta8Aru4vNQMDgbeAL5J+Mzev6+sDeBG4NGrnRdtZtl8nXS/Z3uWrAHZkLNdFfblomLt3fBP0HmBY1M6p5xDtCl1M+jd+TtdsZnEzexvYC6wivbfS6O7JburqrDla3wQMPbMVn1y2A9UvefrXZM5Nj5pZMfDfwN+5+8HMdblYs7u3u/sUoBK4BLggyyWdtmwHaicwKmO5MurLRX82sxEA0fXeqD8nnoOZ5ZMO05Pu/mzUndM1d3D3RuBl0rt4ZWbWcUpcZl2dNUfrS4H9Z7jUk8p2oN4ExkUzOwWkDzZXZrmmE1kJ3Ba1byN9nNLRf2s0czYdaMrYzTojLP1Hz5cCW9z9xxmrcrnmcjMri9oDSB/zbSEdrBtOUHPHc7kBWBONurkl2wdxpGecPiC9//yDbNcT1fQrYDfQRno//g7S++urgQ+Bl4Ah0bYG/Cyq/x2gOgv1Xk56d24T8HZ0+UqO13whsDGqeTPwT1H/+cB6oBb4NZCI+guj5dpo/fnZfp10d9GZEiIBZXuXT+SsokCJBKRAiQSkQIkEpECJBKRAiQSkQIkEpECJBPT/RY6a2zTeU2cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwgcy0o3BoNx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}